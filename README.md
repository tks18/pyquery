<div align="center">

# âš¡ PyQuery: The CEO of ETL ğŸ

[![Status](https://img.shields.io/badge/Status-Main_Character_Energy-%23FF0055?style=for-the-badge&logo=appveyor)](https://github.com/tks18/pyquery)
[![RAM Usage](https://img.shields.io/badge/RAM_Usage-Low_Key_Zero-%2300ffa3?style=for-the-badge&logo=nvidia)](https://pola.rs)
[![Engine](https://img.shields.io/badge/Engine-Polars_Supremacy_ğŸ»â€â„ï¸-%23ffcc00?style=for-the-badge&logo=polars)](https://pola.rs)
[![Vibe](https://img.shields.io/badge/Vibe-Immaculate_âœ¨-%238A2BE2?style=for-the-badge)](https://github.com/tks18/pyquery)

**Your laptop fan shouldn't sound like a Boeing 747. âœˆï¸**<br>
Build **Big Data Pipelines** on a toaster. ğŸ§¯

[Feature Request](https://github.com/tks18/pyquery/issues) Â· [Report Bug](https://github.com/tks18/pyquery/issues)

</div>

---

## ğŸ“– The Lore (Why I built this)

Let's keep it 100. **Pandas is cooked.** ğŸ’€

I was tired of `MemoryError`. I was tired of my laptop freezing when I opened a 2GB CSV. I was tired of writing 50 lines of boilerplate just to rename a column. It was giving **NPC energy**.

I wanted a tool that:

1.  **Mogs Big Data**: Handles 100GB+ files without sweating.
2.  **Looks Good**: Because I'm not staring at a terminal from 1995.
3.  **Just Works**: No "dependency hell". No "setup rituals".

So I built **PyQuery**. It's the **Chad Data Engine** vs the **Virgin Excel Sheet**.

---

## ğŸ§  Why PyQuery Slaps (The Technical Rizz)

We didn't just wrap a library. We built a **Streaming Architecture**.

### 1. ğŸŒŠ The "Infinite Stream" Glitch (Lazy Execution)

Most tools (Pandas, Excel) are **Eager**. They try to load the entire file into RAM.
_Result_: Your RAM fills up, your swap file explodes, and your PC takes a screenshot. ğŸ“¸

**PyQuery is Lazy.**

- **Step 1 (Scan)**: We read the file header. "Okay, it's a 50GB file. Cool."
- **Step 2 (Plan)**: You add filters, joins, math. We don't run them yet. We build a **Query Plan**.
- **Step 3 (Stream)**: When you hit "Export", we pull data in **Chunks** (e.g., 50MB at a time).
  - Chunk comes in â¡ï¸ Process â¡ï¸ Write to Output â¡ï¸ Delete from RAM.
  - Repeat.

**The Flex**: You can process a **100GB dataset** on an **8GB MacBook Air**. The RAM usage stays flat line. ğŸ“‰

### 2. ğŸ›¡ï¸ Type Safety (We don't do 'NoneType' errors)

Python is dynamic (unsafe). We made it strict.

- Every single step is backed by a **Pydantic Model**.
- If you try to put a `String` into a `Float` column, the app stops you **before** execution.
- No more waking up to a failed job at 3 AM. We catch the L's early.

### 3. ğŸ§© The Plugin System

Complete decoupling.

- **Core**: The Engine knows nothing about specific transforms.
- **Registry**: Plugins register themselves.
- **UI**: Auto-generated from the Pydantic models.
  Want to add a custom ML model? Write a function, register it. **Boom.** It's in the app.

---

## ğŸ’¹ Benchmarks (Receipts) ğŸ§¾

| Metric            | ğŸ¼ Pandas (Legacy)       | âš¡ PyQuery (Polars)     | The Diff       |
| :---------------- | :----------------------- | :---------------------- | :------------- |
| **Load 10GB CSV** | `MemoryError` (Crash) ğŸ’¥ | **0.2s** (Lazy Scan) âš¡ | **Infinite**   |
| **Filter Rows**   | 15.4s (Slow)             | **0.5s** (Parallel)     | **30x Faster** |
| **Group By**      | 45s (Painful)            | **2.1s** (Instant)      | **20x Faster** |
| **RAM Usage**     | 12GB+ (Bloated)          | **500MB** (Lean)        | **95% Less**   |

_Benchmarks run on a standard dev laptop. Results may vary but the vibe remains consistent._

---

## ğŸ§° The Toolkit (Loadout)

We packed this thing with every tool you need to clear the map.

### ğŸ“¥ **Universal Ingest (The Source)**

- **Files**: CSV, Excel (`.xlsx`), Parquet, JSON, Arrow IPC.
- **Bulk Mode**: Drag & Drop 50 files. We scan them as a single dataset.
- **Staged Loader**: Even Excel files are streamed to Parquet first.

### ğŸ§ª **Transformation Laboratory**

| Category      | The Tools                                   | Why it slaps                            |
| :------------ | :------------------------------------------ | :-------------------------------------- |
| **Cleaning**  | `Fill Nulls`, `Clean Cast`, `Regex Extract` | Turns garbage data into gold. âœ¨        |
| **Analytics** | `Rolling Agg`, `Time Bin`, `Rank`, `Diff`   | High-frequency trading vibes. ğŸ“ˆ        |
| **Combining** | `Smart Join`, `Concat`, `Pivot`             | Merge datasets without the headache. ğŸ¤ |
| **Math**      | `Log`, `Exp`, `Clip`, `Date Offset`         | For the scientific girlies. ğŸ‘©â€ğŸ”¬          |
| **Text**      | `Slice`, `Case`, `Replace`                  | String manipulation on steroids. ğŸ’ª     |

### ğŸ“¤ **Export (Secure the Bag)**

- **Async Jobs**: Exports run in the background. Don't block the UI.
- **Formats**:
  - **Parquet**: The G.O.A.T format (Compression + Speed).
  - **SQL**: Push straight to prod DB.
  - **NDJSON**: For structured logging.

---

## ğŸ§‘â€ğŸ’» Developer Guide (Hacking)

Want to add a feature? It's open source. **Fork it.**

### Adding a new Transform (The 4-Step Method)

1.  **Define Params**: Create a Pydantic model in `params.py`.
2.  **Logic**: Write a pure polars function in `transforms/`.
3.  **UI**: Write a Streamlit renderer (Use callbacks, don't be lazy!).
4.  **Register**: Add one line to `engine.py`.

```python
StepRegistry.register("my_feature", ..., MyParams, my_func, my_ui)
```

---

## ğŸ—ºï¸ Roadmap (Manifesting)

We aren't creating a roadmap, we are creating a legacy.

- [x] **Phase 1**: Base Engine (Polars + Streamlit) âœ…
- [x] **Phase 2**: Big Data Streaming (Lazy Exec) âœ…
- [x] **Phase 3**: Registry System (Plugins) âœ…

---

## â“ FAQ (Real Questions)

**Q: Can I load a 100GB file?**
A: Yes. It will stream through. Just make sure you have disk space.

**Q: Is this Web Scale?**
A: It's built on Rust. It's faster than your web app.

**Q: Why not just use Excel?**
A: If you like waiting 10 minutes for a VLOOKUP, go ahead. We don't judge. (We do).

---

## ğŸš€ How to Run

Don't be basic.

### 1. Clone it

```bash
git clone https://github.com/tks18/pyquery.git
cd pyquery
```

### 2. Install deps

We use `uv` because `pip` is slow.

```bash
uv sync  # or
pip install -r requirements.txt
```

### 3. Launch

Let's gooo! ğŸï¸

```bash
streamlit run app.py
```

---

## ğŸ¤ Contributing

**PRs are welcome.**

- Found a bug? **L.** Open an issue.
- Fixed it? **W.** Submit a PR.
- Added a feature? **Goated.** ğŸ

## ğŸ“œ License

**GPL-3.0**. We don't gatekeep. Open source forever. ğŸ’–

---

<div align="center">

_Made with â˜•, ğŸ¦€ (Rust), and ğŸ’– by [Sudharshan TK](https://github.com/tks18)_

</div>
